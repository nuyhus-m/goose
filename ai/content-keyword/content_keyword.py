from fastapi import FastAPI, HTTPException
from pydantic import BaseModel
import re
from konlpy.tag import Okt
import spacy
from collections import Counter
from fastapi.middleware.cors import CORSMiddleware

# âœ… FastAPI ì„œë²„ ì´ˆê¸°í™”
app = FastAPI()

# CORS ì„¤ì • ì¶”ê°€
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],  # ëª¨ë“  ë„ë©”ì¸ í—ˆìš© (ë³´ì•ˆ í•„ìš”ì‹œ íŠ¹ì • ë„ë©”ì¸ìœ¼ë¡œ ë³€ê²½)
    allow_credentials=True,
    allow_methods=["*"],  # ëª¨ë“  HTTP ë©”ì„œë“œ í—ˆìš© (GET, POST ë“±)
    allow_headers=["*"],  # ëª¨ë“  HTTP í—¤ë” í—ˆìš©
)

# âœ… í•œêµ­ì–´ ìì—°ì–´ì²˜ë¦¬ ì—”ì§„ ë¡œë“œ (KoNLPy + spaCy)
okt = Okt()
try:
    nlp = spacy.load("ko_core_news_sm")  # í•œêµ­ì–´ NLP ëª¨ë¸
except Exception:
    raise RuntimeError("âŒ spaCy 'ko_core_news_sm' ëª¨ë¸ì´ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. ì„¤ì¹˜ í›„ ë‹¤ì‹œ ì‹¤í–‰í•˜ì„¸ìš”.")

# âœ… ë¶ˆìš©ì–´ ë¦¬ìŠ¤íŠ¸ ë³‘í•© (KoNLPy + spaCy + Custom)
konlpy_stopwords = {"ì˜", "ê°€", "ì´", "ì€", "ë“¤", "ëŠ”", "ì¢€", "ì˜", "ê±", "ê³¼", "ë„", "ë¥¼", "ìœ¼ë¡œ", "ì", "ì—", "ì™€", "í•œ", "í•˜ë‹¤"}
custom_stopwords = {"ë‰´ìŠ¤", "ê¸°ì‚¬", "ì‚¬ì§„", "ì¶œì²˜", "ì—°í•©ë‰´ìŠ¤", "ë“±", "ëŒ€í•œ", "ë°", "í•˜ëŠ”", "ê·¸", "ì´", "ì €", "ë“±ë“±", "...", "â€˜", "â€™", "â€œ", "â€"}

# âœ… spaCy í•œêµ­ì–´ ë¶ˆìš©ì–´ ì˜ˆì™¸ ì²˜ë¦¬
try:
    spacy_stopwords = set(nlp.Defaults.stop_words)  # spaCy í•œêµ­ì–´ ë¶ˆìš©ì–´
except AttributeError:
    spacy_stopwords = set()

# âœ… ìµœì¢… ë¶ˆìš©ì–´ ë¦¬ìŠ¤íŠ¸ ë³‘í•©
stopwords_set = konlpy_stopwords | spacy_stopwords | custom_stopwords

class KeywordRequest(BaseModel):
    text: str  # titles -> textë¡œ ë³€ê²½

def clean_text(text: str) -> str:
    """ ğŸ”¹ í…ìŠ¤íŠ¸ì—ì„œ HTML ì—”í‹°í‹°, íŠ¹ìˆ˜ë¬¸ì, ì¤„ë°”ê¿ˆ ë¬¸ì ì œê±° """
    text = re.sub(r"&quot;|&amp;|&lt;|&gt;", "", text)  # HTML ì—”í‹°í‹° ì œê±°
    text = re.sub(r"\n", " ", text)  # ì¤„ë°”ê¿ˆ ë¬¸ì(\n) ê³µë°±ìœ¼ë¡œ ë³€ê²½
    text = re.sub(r"[^ê°€-í£a-zA-Z0-9\s]", "", text)  # íŠ¹ìˆ˜ë¬¸ì ì œê±°
    return text.strip()

@app.post("/content_keywords")
async def extract_keywords_nltk(request: KeywordRequest):
    try:
        # âœ… ìš”ì²­ì—ì„œ ë°›ì€ textë§Œ ì‚¬ìš©
        full_text = clean_text(request.text)

        print("ğŸ”¹ [OCR í…ìŠ¤íŠ¸ ë³€í™˜ ì™„ë£Œ] full_text:", full_text)

        # âœ… í† í°í™” (KoNLPy + spaCy)
        tokens = okt.morphs(full_text) + [token.text for token in nlp(full_text)]

        # âœ… ë¶ˆìš©ì–´ ì œê±° ë° ëª…ì‚¬ í•„í„°ë§
        keywords = [word for word in tokens if word not in stopwords_set and len(word) > 1]

        # âœ… ë¹ˆë„ìˆ˜ ê¸°ë°˜ ìƒìœ„ 3ê°œ í‚¤ì›Œë“œ ì„ íƒ
        keyword_counts = Counter(keywords)
        top_keywords = [word for word, count in keyword_counts.most_common(3)]
        print("ğŸ”¹ [ì¶”ì¶œëœ í‚¤ì›Œë“œ] top_keywords:", top_keywords)

        return {"keywords": top_keywords}

    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))
