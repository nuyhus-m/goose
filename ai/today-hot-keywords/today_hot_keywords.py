from fastapi import FastAPI, HTTPException
from pydantic import BaseModel
from typing import List
import re
import nltk
from nltk.corpus import stopwords
from konlpy.tag import Okt
import spacy
from collections import Counter

# âœ… FastAPI ì„œë²„ ì´ˆê¸°í™”
app = FastAPI()

# âœ… í•œêµ­ì–´ ìì—°ì–´ì²˜ë¦¬ ì—”ì§„ ë¡œë“œ (NLTK + KoNLPy + spaCy)
nltk.download("punkt")
nltk.download("stopwords")
okt = Okt()
try:
    nlp = spacy.load("ko_core_news_sm")  # í•œêµ­ì–´ NLP ëª¨ë¸
except Exception:
    raise RuntimeError("âŒ spaCy 'ko_core_news_sm' ëª¨ë¸ì´ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. ì„¤ì¹˜ í›„ ë‹¤ì‹œ ì‹¤í–‰í•˜ì„¸ìš”.")

# âœ… ë¶ˆìš©ì–´ ë¦¬ìŠ¤íŠ¸ ë³‘í•© (KoNLPy + spaCy + Custom)
konlpy_stopwords = {"ì˜", "ê°€", "ì´", "ì€", "ë“¤", "ëŠ”", "ì¢€", "ì˜", "ê±", "ê³¼", "ë„", "ë¥¼", "ìœ¼ë¡œ", "ì", "ì—", "ì™€", "í•œ", "í•˜ë‹¤"}
custom_stopwords = {"ë‰´ìŠ¤", "ê¸°ì‚¬", "ì‚¬ì§„", "ì¶œì²˜", "ì—°í•©ë‰´ìŠ¤", "ë“±", "ëŒ€í•œ", "ë°", "í•˜ëŠ”", "ê·¸", "ì´", "ì €", "ë“±ë“±", "...", "â€˜", "â€™", "â€œ", "â€"}

# âœ… spaCy í•œêµ­ì–´ ë¶ˆìš©ì–´ ì˜ˆì™¸ ì²˜ë¦¬
try:
    spacy_stopwords = set(nlp.Defaults.stop_words)  # spaCy í•œêµ­ì–´ ë¶ˆìš©ì–´
except AttributeError:
    spacy_stopwords = set()

# âœ… ìµœì¢… ë¶ˆìš©ì–´ ë¦¬ìŠ¤íŠ¸ ë³‘í•©
stopwords_set = konlpy_stopwords | spacy_stopwords | custom_stopwords

class KeywordRequest(BaseModel):
    titles: List[str]

def clean_text(text: str) -> str:
    """ ğŸ”¹ í…ìŠ¤íŠ¸ì—ì„œ HTML ì—”í‹°í‹°, íŠ¹ìˆ˜ë¬¸ì ì œê±° """
    text = re.sub(r"&quot;|&amp;|&lt;|&gt;", "", text)  # HTML ì—”í‹°í‹° ì œê±°
    text = re.sub(r"[^ê°€-í£a-zA-Z0-9\s]", "", text)  # íŠ¹ìˆ˜ë¬¸ì ì œê±°
    return text.strip()

@app.post("/today-hot-keywords")
async def extract_keywords_nltk(request: KeywordRequest):
    try:
        # âœ… ë‰´ìŠ¤ ì œëª©ì„ í•˜ë‚˜ì˜ ë¬¸ì¥ìœ¼ë¡œ í•©ì¹¨
        full_text = " ".join([clean_text(title) for title in request.titles if len(title) > 5])

        print("ğŸ”¹ [ì „ì²˜ë¦¬ ì™„ë£Œ] full_text:", full_text)  # ë””ë²„ê¹…ìš© ë¡œê·¸

        # âœ… í† í°í™” (KoNLPy + spaCy)
        tokens = okt.morphs(full_text) + [token.text for token in nlp(full_text)]

        # âœ… ë¶ˆìš©ì–´ ì œê±° ë° ëª…ì‚¬ í•„í„°ë§
        keywords = [word for word in tokens if word not in stopwords_set and len(word) > 1]

        # âœ… ë¹ˆë„ìˆ˜ ê¸°ë°˜ ìƒìœ„ 10ê°œ í‚¤ì›Œë“œ ì„ íƒ
        keyword_counts = Counter(keywords)
        top_keywords = [word for word, count in keyword_counts.most_common(10)]
        print("ğŸ”¹ [ì¶”ì¶œëœ í‚¤ì›Œë“œ] top_keywords:", top_keywords)

        return {"keywords": top_keywords}

    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))
