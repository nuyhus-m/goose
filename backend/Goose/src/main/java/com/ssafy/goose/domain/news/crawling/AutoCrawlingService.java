package com.ssafy.goose.domain.news.crawling;

import com.ssafy.goose.domain.news.dto.NewsArticleDto;
import com.ssafy.goose.domain.news.entity.NewsArticle;
import com.ssafy.goose.domain.news.repository.NewsRepository;
import org.springframework.beans.factory.annotation.Value;
import org.springframework.http.*;
import org.springframework.scheduling.annotation.Scheduled;
import org.springframework.stereotype.Service;
import org.springframework.web.client.RestTemplate;

import java.time.LocalDateTime;
import java.util.*;
import java.util.stream.Collectors;

@Service
public class AutoCrawlingService {

    @Value("${naver.client-id}")
    private String clientId;

    @Value("${naver.client-secret}")
    private String clientSecret;

    private final RestTemplate restTemplate = new RestTemplate();

    private final NewsRepository newsRepository;

    private final NewsContentScraping newsContentScraping;

    public AutoCrawlingService(NewsRepository newsRepository, NewsContentScraping newsContentScraping) {
        this.newsRepository = newsRepository;
        this.newsContentScraping = newsContentScraping;
    }

    /**
     * ğŸ”¹ 1. ë„¤ì´ë²„ ë‰´ìŠ¤ APIë¡œ ìµœì‹  ë‰´ìŠ¤ ì œëª©ì—ì„œ í‚¤ì›Œë“œ ì¶”ì¶œ
     */
    public List<String> extractTrendingKeywords() {
        String url = "https://openapi.naver.com/v1/search/news.json?query=ë‰´ìŠ¤&display=50&sort=date";

        HttpHeaders headers = new HttpHeaders();
        headers.set("X-Naver-Client-Id", clientId);
        headers.set("X-Naver-Client-Secret", clientSecret);

        HttpEntity<String> entity = new HttpEntity<>(headers);
        ResponseEntity<Map> response = restTemplate.exchange(url, HttpMethod.GET, entity, Map.class);

        List<Map<String, Object>> newsItems = (List<Map<String, Object>>) response.getBody().get("items");
        List<String> titles = newsItems.stream()
                .map(item -> ((String) item.get("title")).replaceAll("<[^>]*>", "")) // HTML íƒœê·¸ ì œê±°
                .collect(Collectors.toList());

        return extractKeywordsFromTitles(titles);
    }

    /**
     * ğŸ”¹ 2. ë‰´ìŠ¤ ì œëª©ì—ì„œ ì£¼ìš” í‚¤ì›Œë“œ ì¶”ì¶œ (ë¹ˆë„ ê¸°ë°˜)
     */
    private List<String> extractKeywordsFromTitles(List<String> titles) {
        Map<String, Integer> wordCount = new HashMap<>();

        for (String title : titles) {
            String[] words = title.split("\\s+");
            for (String word : words) {
                word = word.replaceAll("[^ê°€-í£a-zA-Z0-9]", "").trim(); // íŠ¹ìˆ˜ë¬¸ì ì œê±°
                if (word.length() > 1) { // 1ê¸€ì ì´í•˜ ë‹¨ì–´ ì œì™¸
                    wordCount.put(word, wordCount.getOrDefault(word, 0) + 1);
                }
            }
        }

        return wordCount.entrySet().stream()
                .sorted((a, b) -> b.getValue().compareTo(a.getValue())) // ë¹ˆë„ìˆ˜ ê¸°ì¤€ ì •ë ¬
                .limit(10) // ìƒìœ„ 10ê°œ í‚¤ì›Œë“œ ì„ íƒ
                .map(Map.Entry::getKey)
                .collect(Collectors.toList());
    }

    /**
     * ğŸ”¹ 3. ë„¤ì´ë²„ ë‰´ìŠ¤ APIë¡œ ë‰´ìŠ¤ ë°ì´í„° ê°€ì ¸ì˜¤ê¸°
     */
    public Map<String, Object> getNews(String query) {
        String url = "https://openapi.naver.com/v1/search/news.json?query=" + query
                + "&display=20&sort=sim";

        HttpHeaders headers = new HttpHeaders();
        headers.set("X-Naver-Client-Id", clientId);
        headers.set("X-Naver-Client-Secret", clientSecret);

        HttpEntity<String> entity = new HttpEntity<>(headers);
        ResponseEntity<Map> response = restTemplate.exchange(url, HttpMethod.GET, entity, Map.class);

        return response.getBody();
    }

    /**
     * ğŸ”¹ 4. 6ì‹œê°„ë§ˆë‹¤ ìë™ ì‹¤í–‰í•˜ì—¬ MongoDBì— ë‰´ìŠ¤ ì €ì¥
     */
    @Scheduled(cron = "0 40 18 * * *", zone = "Asia/Seoul")
    public void fetchAndSaveTrendingNews() {
        System.out.println("ğŸ•’ ë‰´ìŠ¤ í¬ë¡¤ë§ ì‹¤í–‰: " + LocalDateTime.now());

        List<String> trendingKeywords = extractTrendingKeywords(); // ğŸ”¹ ìµœì‹  ë‰´ìŠ¤ì—ì„œ í‚¤ì›Œë“œ ì¶”ì¶œ

        for (String keyword : trendingKeywords) {
            System.out.println("ğŸ” ê²€ìƒ‰ì–´: " + keyword);
            Map<String, Object> newsData = getNews(keyword);
            saveNewsToMongoDB(newsData);
        }

        System.out.println("âœ… ë‰´ìŠ¤ ì €ì¥ ì™„ë£Œ!");
    }

    /**
     * ğŸ”¹ 5. MongoDBì— ë‰´ìŠ¤ ì €ì¥ (ë³¸ë¬¸ ê¸¸ì´ 100 ì´ìƒ í•„í„°ë§ ì¶”ê°€)
     */
    public void saveNewsToMongoDB(Map<String, Object> newsData) {
        List<Map<String, Object>> newsItems = (List<Map<String, Object>>) newsData.get("items");

        for (Map<String, Object> item : newsItems) {
            String url = (String) item.get("link");
            Map<String, Object> scrapingResult = newsContentScraping.extractArticle(url);

            if (scrapingResult == null) {
                System.out.println("âŒ í¬ë¡¤ë§ ì‹¤íŒ¨: " + url);
                continue;
            }

            String content = (String) scrapingResult.get("text");
            if (content == null || content.length() < 100) {
                System.out.println("âš ï¸ ë³¸ë¬¸ì´ ë„ˆë¬´ ì§§ì•„ ì €ì¥í•˜ì§€ ì•ŠìŒ (ê¸¸ì´: " + (content != null ? content.length() : 0) + ")");
                continue;
            }

            NewsArticle article = NewsArticle.builder()
                    .title((String) item.get("title"))
                    .originalLink((String) item.get("originallink"))
                    .naverLink(url)
                    .description((String) item.get("description"))
                    .pubDate((String) item.get("pubDate"))
                    .content(content)  // ë³¸ë¬¸ í¬ë¡¤ë§ (100ì ì´ìƒ)
                    .topImage((String) scrapingResult.get("image")) // ëŒ€í‘œ ì´ë¯¸ì§€
                    .extractedAt(LocalDateTime.now())
                    .build();


            newsRepository.save(article);
        }
    }
}
